#!/usr/bin/env python3
"""
Fix Agents Script - Automated remediation for generated agent files.

This script:
1. Scans .claude/agents/ for agent markdown files
2. Detects files generated by triads-generator
3. Fixes common issues (missing frontmatter, invalid format)
4. Creates backups before making changes
5. Reports results

Usage:
    python3 fix_agents.py [--auto-confirm] [--backup-dir DIR]
"""

import json
import re
import shutil
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple


class AgentFixer:
    """Fix common issues in generated agent files."""

    def __init__(self, project_root: Path = Path('.'), force_all: bool = False):
        """
        Initialize the agent fixer.

        Args:
            project_root: Path to project root (where .claude/ is located)
            force_all: If True, fix all files even if not generated by us
        """
        self.project_root = project_root
        self.agents_dir = project_root / '.claude' / 'agents'
        self.settings_file = project_root / '.claude' / 'settings.json'
        self.backup_root = self.agents_dir / '.backups'
        self.force_all = force_all

        self.generated_files: Set[str] = set()
        self.issues: Dict[str, List[str]] = {}
        self.user_files: Set[str] = set()

    def load_manifest(self) -> Set[str]:
        """
        Load list of generated files from settings.json.

        Returns:
            Set of file paths that were generated
        """
        if not self.settings_file.exists():
            return set()

        try:
            with open(self.settings_file) as f:
                settings = json.load(f)

            metadata = settings.get('generator_metadata', {})
            files = metadata.get('files_generated', [])

            # Convert to set for fast lookup
            return {str(Path(f)) for f in files if f.endswith('.md')}
        except (json.JSONDecodeError, KeyError):
            return set()

    def is_generated_file(self, file_path: Path) -> bool:
        """
        Check if a file was generated by triads-generator.

        Uses multiple detection methods:
        1. Manifest check (settings.json)
        2. Frontmatter check (generated_by field)
        3. Pattern detection (legacy files)

        Args:
            file_path: Path to agent file

        Returns:
            True if file was generated by us
        """
        relative_path = str(file_path.relative_to(self.project_root))

        # Method 1: Check manifest
        if relative_path in self.generated_files:
            return True

        # Method 2: Check frontmatter
        content = file_path.read_text()
        if 'generated_by: triads-generator' in content:
            return True

        # Method 3: Pattern detection for legacy files
        # Generated files typically start with "# {Agent Name}" after frontmatter
        # and have specific section structure
        if re.search(r'^# [A-Z][a-z]+(?: [A-Z][a-z]+)*$', content, re.MULTILINE):
            if '## Identity & Purpose' in content:
                if '## Your Workflow' in content or '## Triad Context' in content:
                    return True

        return False

    def parse_frontmatter(self, content: str) -> Tuple[Optional[Dict], str]:
        """
        Parse YAML frontmatter from markdown content.

        Args:
            content: Markdown file content

        Returns:
            Tuple of (frontmatter dict or None, body content)
        """
        if not content.startswith('---\n'):
            return None, content

        # Find end of frontmatter
        match = re.search(r'\n---\n', content[4:])
        if not match:
            return None, content

        end_pos = match.start() + 4
        frontmatter_text = content[4:end_pos]
        body = content[end_pos + 4:]  # Skip past "---\n"

        # Parse YAML (simple key: value format)
        frontmatter = {}
        for line in frontmatter_text.strip().split('\n'):
            if ':' in line:
                key, value = line.split(':', 1)
                frontmatter[key.strip()] = value.strip()

        return frontmatter, body

    def derive_agent_info(self, file_path: Path) -> Dict[str, str]:
        """
        Derive agent information from file path.

        Args:
            file_path: Path to agent file

        Returns:
            Dict with name, triad, role
        """
        # Path structure: .claude/agents/{triad}/{agent}.md
        parts = file_path.parts
        agent_name = file_path.stem
        triad_name = parts[-2] if len(parts) >= 2 else 'unknown'

        # Derive role from agent name
        role_map = {
            'gatherer': 'gatherer',
            'analyzer': 'analyzer',
            'analyst': 'analyst',
            'researcher': 'researcher',
            'documenter': 'documenter',
            'verifier': 'verifier',
            'architect': 'architect',
            'educator': 'educator',
            'checker': 'checker',
        }

        role = 'agent'  # default
        for keyword, role_name in role_map.items():
            if keyword in agent_name:
                role = role_name
                break

        # Derive description from agent name and role
        description = self.derive_description(agent_name, role, triad_name)

        return {
            'name': agent_name,
            'triad': triad_name,
            'role': role,
            'description': description
        }

    def derive_description(self, agent_name: str, role: str, triad_name: str) -> str:
        """
        Derive a description from agent name and role.

        Args:
            agent_name: Agent file stem
            role: Agent role
            triad_name: Triad directory name

        Returns:
            One-line description string
        """
        # Convert names to title case
        agent_title = agent_name.replace('_', ' ').title()
        triad_title = triad_name.replace('_', ' ').title()

        # Role-specific description templates
        role_templates = {
            'gatherer': f"Gathers information for {triad_title}",
            'analyzer': f"Analyzes data for {triad_title}",
            'analyst': f"Performs analysis for {triad_title}",
            'researcher': f"Researches and documents for {triad_title}",
            'documenter': f"Documents findings for {triad_title}",
            'verifier': f"Verifies information for {triad_title}",
            'architect': f"Designs solutions for {triad_title}",
            'educator': f"Presents educational content for {triad_title}",
            'checker': f"Validates compliance for {triad_title}",
        }

        return role_templates.get(role, f"{agent_title} agent for {triad_title}")

    def check_file(self, file_path: Path) -> List[str]:
        """
        Check an agent file for issues.

        Args:
            file_path: Path to agent file

        Returns:
            List of issue descriptions
        """
        issues = []
        content = file_path.read_text()

        # Check for frontmatter
        frontmatter, body = self.parse_frontmatter(content)

        if frontmatter is None:
            issues.append('missing_frontmatter')
        else:
            # Check required fields
            required_fields = ['name', 'triad', 'role', 'description']
            for field in required_fields:
                if field not in frontmatter:
                    issues.append(f'missing_field_{field}')

            # Check if it has generator metadata
            if 'generated_by' not in frontmatter:
                issues.append('missing_generator_metadata')

        return issues

    def fix_file(self, file_path: Path, issues: List[str]) -> bool:
        """
        Fix issues in an agent file.

        Args:
            file_path: Path to agent file
            issues: List of issues to fix

        Returns:
            True if file was modified
        """
        content = file_path.read_text()
        frontmatter, body = self.parse_frontmatter(content)
        agent_info = self.derive_agent_info(file_path)

        # Build new frontmatter
        new_frontmatter = {}

        if frontmatter:
            # Preserve existing frontmatter
            new_frontmatter = frontmatter.copy()

        # Add/update required fields
        new_frontmatter['name'] = new_frontmatter.get('name', agent_info['name'])
        new_frontmatter['triad'] = new_frontmatter.get('triad', agent_info['triad'])
        new_frontmatter['role'] = new_frontmatter.get('role', agent_info['role'])
        new_frontmatter['description'] = new_frontmatter.get('description', agent_info['description'])

        # Add generator metadata if missing
        if 'generated_by' not in new_frontmatter:
            new_frontmatter['generated_by'] = 'triads-generator'
            new_frontmatter['generator_version'] = '0.4.2'
            new_frontmatter['generated_at'] = datetime.now().isoformat()

        # Build new content
        frontmatter_text = '---\n'
        for key, value in new_frontmatter.items():
            frontmatter_text += f'{key}: {value}\n'
        frontmatter_text += '---\n\n'

        new_content = frontmatter_text + body.lstrip()

        # Write back
        file_path.write_text(new_content)

        return True

    def scan(self) -> None:
        """Scan agents directory and identify issues."""
        if not self.agents_dir.exists():
            print(f"❌ Agents directory not found: {self.agents_dir}")
            sys.exit(1)

        # Load manifest
        self.generated_files = self.load_manifest()

        # Scan all markdown files
        agent_files = list(self.agents_dir.rglob('*.md'))

        for file_path in agent_files:
            # Skip backup directory
            if '.backups' in file_path.parts:
                continue

            # Check if generated by us
            is_generated = self.is_generated_file(file_path)

            if not is_generated and not self.force_all:
                # Not generated and not forcing - skip
                self.user_files.add(str(file_path.relative_to(self.project_root)))
                continue

            # Check for issues
            issues = self.check_file(file_path)
            if issues:
                self.issues[str(file_path.relative_to(self.project_root))] = issues

            # Track as user file if not generated (for reporting)
            if not is_generated:
                self.user_files.add(str(file_path.relative_to(self.project_root)))

    def create_backup(self) -> Path:
        """
        Create backup of agents directory.

        Returns:
            Path to backup directory
        """
        timestamp = datetime.now().strftime('%Y-%m-%dT%H-%M-%S')
        backup_dir = self.backup_root / timestamp
        backup_dir.mkdir(parents=True, exist_ok=True)

        # Copy all agent files
        for file_path in self.agents_dir.rglob('*.md'):
            if '.backups' in file_path.parts:
                continue

            relative_path = file_path.relative_to(self.agents_dir)
            backup_file = backup_dir / relative_path
            backup_file.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(file_path, backup_file)

        return backup_dir

    def report(self) -> None:
        """Print scan report."""
        total_files = len(self.issues) + len(self.user_files)
        generated_count = len(self.issues) + len([f for f in self.generated_files if f.endswith('.md')])

        print(f"\nScanning {self.agents_dir}...\n")
        print(f"Found {total_files} agent files:")
        print(f"  ✓ {generated_count} generated by triads-generator")

        if self.user_files:
            print(f"  ⚠️  {len(self.user_files)} user-created (skipping)")
            for file_path in sorted(self.user_files):
                print(f"     - {file_path}")

        print()

        if not self.issues:
            print("✅ No issues found! All agent files are properly formatted.\n")
            return

        # Count issue types
        issue_types = {}
        for issues in self.issues.values():
            for issue in issues:
                issue_types[issue] = issue_types.get(issue, 0) + 1

        print("Issues found:")
        for issue_type, count in sorted(issue_types.items()):
            issue_name = issue_type.replace('_', ' ').title()
            print(f"  - {count} agents with {issue_name}")

        print(f"\nFiles that will be modified:")
        for file_path in sorted(self.issues.keys()):
            print(f"  {file_path}")
        print()

    def fix_all(self, auto_confirm: bool = False) -> None:
        """
        Fix all identified issues.

        Args:
            auto_confirm: Skip confirmation prompt
        """
        if not self.issues:
            return

        # Check if we're fixing non-generated files
        non_generated_count = len([f for f in self.issues.keys() if f in [str(Path(u)) for u in self.user_files]])

        if not auto_confirm:
            if non_generated_count > 0 and self.force_all:
                print(f"\n⚠️  WARNING: {non_generated_count} of {len(self.issues)} files are NOT generated by triads-generator.")
                print("These may be your custom agent files.")
                print("\nForcing fixes will:")
                print("  - Add/update frontmatter fields (name, triad, role, description)")
                print("  - Add generator metadata (generated_by, generator_version, generated_at)")
                print("  - Create backups before modifying")
                print("\nFiles that will be modified:")
                for file_path in sorted(self.issues.keys()):
                    if file_path in [str(Path(u)) for u in self.user_files]:
                        print(f"  ⚠️  {file_path}")
                print()

            response = input(f"Fix {len(self.issues)} agent files? [y/n]: ")
            if response.lower() != 'y':
                print("Aborted.")
                sys.exit(0)

        # Create backup
        print("\nCreating backup...")
        backup_dir = self.create_backup()
        print(f"✓ Backup saved to: {backup_dir.relative_to(self.project_root)}\n")

        # Fix each file
        fixed_count = 0
        for file_path_str, issues in self.issues.items():
            file_path = self.project_root / file_path_str

            try:
                self.fix_file(file_path, issues)
                print(f"✓ Fixed {file_path.name} ({', '.join(issues)})")
                fixed_count += 1
            except Exception as e:
                print(f"❌ Failed to fix {file_path.name}: {e}")

        print(f"\n✅ Fixed {fixed_count} agent files")
        print(f"Backups saved to: {backup_dir.relative_to(self.project_root)}/\n")
        print("Run /doctor to verify all issues are resolved.")


def main():
    """Main entry point."""
    import argparse

    parser = argparse.ArgumentParser(description='Fix generated agent files')
    parser.add_argument('--auto-confirm', action='store_true',
                        help='Skip confirmation prompt')
    parser.add_argument('--force', action='store_true',
                        help='Fix ALL files including non-generated ones (requires confirmation)')
    parser.add_argument('--project-root', type=Path, default=Path('.'),
                        help='Path to project root (default: current directory)')

    args = parser.parse_args()

    # Initialize fixer
    fixer = AgentFixer(project_root=args.project_root, force_all=args.force)

    # Scan for issues
    fixer.scan()

    # Report findings
    fixer.report()

    # Fix issues
    if fixer.issues:
        fixer.fix_all(auto_confirm=args.auto_confirm)


if __name__ == '__main__':
    main()
